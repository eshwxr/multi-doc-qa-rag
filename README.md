# ðŸ§  Multi-Document Question Answering using RAG

A powerful **Retrieval-Augmented Generation (RAG)** pipeline that enables **question answering over multiple documents** (PDFs, text files, etc.). Built with **LangChain**, **HuggingFace embeddings**, **ChromaDB**, and **Groqâ€™s ultra-fast LLMs**.

---

## ðŸš€ Demo Overview

âœ… Load and chunk multiple PDF/text documents  
âœ… Embed chunks using HuggingFace models  
âœ… Store in ChromaDB (vector DB)  
âœ… Answer questions with Groqâ€™s LLM using retrieved context  

---

## ðŸ“¦ Tech Stack

| Layer         | Tool / API                 |
|---------------|----------------------------|
| Embeddings    | `HuggingFace Transformers` |
| Vector DB     | `Chroma`                   |
| RAG Engine    | `LangChain`                |
| LLM Inference | `Groq`                     |
| Parsing       | `unstructured`, `PyPDF2`   |

---

## ðŸ›  Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/multi-doc-qa-rag.git
cd multi-doc-qa-rag
